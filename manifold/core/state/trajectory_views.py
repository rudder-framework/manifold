"""
Trajectory Views Engine.

Computes per-window views of feature trajectories:
- Fourier view: spectral analysis of feature trajectories
- Hilbert view: envelope (amplitude modulation) of feature trajectories
- Laplacian view: graph coupling structure across signals
- Wavelet view: multi-scale energy distribution of feature trajectories

Pure computation â€” numpy/dict in, dict out. No file I/O.

Delegates to pmtvs primitives for all spectral, wavelet, and correlation math.
"""

import warnings

import numpy as np
from typing import List, Dict

from manifold.primitives.individual.spectral import spectral_profile
from manifold.primitives.individual.hilbert import envelope
from manifold.primitives.individual.stability import wavelet_stability as _wavelet_stability
from manifold.primitives.matrix.graph import laplacian_matrix, laplacian_eigenvalues
from manifold.primitives.pairwise.regression import linear_regression
from manifold.primitives.pairwise.correlation import correlation as _correlation


def compute_fourier_view(
    trajectories: Dict[str, Dict[str, np.ndarray]],
    feature_cols: List[str],
    min_length: int = 8,
) -> Dict[str, float]:
    """
    Fourier view: run spectral_profile on each signal's feature trajectory.
    Aggregate across signals via nanmedian.

    Output keys: fourier_{feature}_dominant_freq, fourier_{feature}_spectral_flatness
    """
    result = {}

    for feat in feature_cols:
        dom_freqs = []
        flatnesses = []

        for sig_trajs in trajectories.values():
            if feat not in sig_trajs:
                continue
            arr = sig_trajs[feat]
            if len(arr) < min_length:
                continue

            sp = spectral_profile(arr)
            dom_freqs.append(sp.get('dominant_frequency', np.nan))
            flatnesses.append(sp.get('spectral_flatness', np.nan))

        result[f'fourier_{feat}_dominant_freq'] = float(np.nanmedian(dom_freqs)) if dom_freqs else np.nan
        result[f'fourier_{feat}_spectral_flatness'] = float(np.nanmedian(flatnesses)) if flatnesses else np.nan

    return result


def compute_hilbert_view(
    trajectories: Dict[str, Dict[str, np.ndarray]],
    feature_cols: List[str],
    min_length: int = 4,
) -> Dict[str, float]:
    """
    Hilbert view: run envelope on each signal's feature trajectory.
    Compute mean, trend, cv. Aggregate across signals via nanmedian.

    Output keys: envelope_{feature}_mean, envelope_{feature}_trend, envelope_{feature}_cv
    """
    result = {}

    for feat in feature_cols:
        means = []
        trends = []
        cvs = []

        for sig_trajs in trajectories.values():
            if feat not in sig_trajs:
                continue
            arr = sig_trajs[feat]
            if len(arr) < min_length:
                continue

            env = envelope(arr)
            m = float(np.mean(env))
            means.append(m)

            if len(env) >= 2:
                slope, _, _, _ = linear_regression(
                    np.arange(len(env), dtype=float), env
                )
                trends.append(float(slope))
            else:
                trends.append(np.nan)

            if m > 0:
                cvs.append(float(np.std(env) / m))
            else:
                cvs.append(np.nan)

        result[f'envelope_{feat}_mean'] = float(np.nanmedian(means)) if means else np.nan
        result[f'envelope_{feat}_trend'] = float(np.nanmedian(trends)) if trends else np.nan
        result[f'envelope_{feat}_cv'] = float(np.nanmedian(cvs)) if cvs else np.nan

    return result


def compute_laplacian_view(
    trajectories: Dict[str, Dict[str, np.ndarray]],
    feature_cols: List[str],
    min_signals: int = 2,
) -> Dict[str, float]:
    """
    Laplacian view: build correlation-based adjacency from concatenated
    feature trajectories, compute graph Laplacian spectrum.

    Output keys: laplacian_algebraic_connectivity, laplacian_spectral_gap,
                 laplacian_n_components, laplacian_max_eigenvalue
    """
    result = {
        'laplacian_algebraic_connectivity': np.nan,
        'laplacian_spectral_gap': np.nan,
        'laplacian_n_components': np.nan,
        'laplacian_max_eigenvalue': np.nan,
    }

    if len(trajectories) < min_signals:
        return result

    # For each signal, concatenate all feature trajectories into one vector
    vectors = []
    for sig_id in sorted(trajectories.keys()):
        parts = []
        for feat in feature_cols:
            if feat in trajectories[sig_id]:
                arr = trajectories[sig_id][feat]
                arr = np.where(np.isfinite(arr), arr, 0.0)
                parts.append(arr)
        if parts:
            vectors.append(np.concatenate(parts))

    if len(vectors) < min_signals:
        return result

    # Pad to same length (signals may have different trajectory lengths)
    max_len = max(len(v) for v in vectors)
    padded = np.zeros((len(vectors), max_len))
    for i, v in enumerate(vectors):
        padded[i, :len(v)] = v

    try:
        # Build adjacency: |correlation| via primitives
        n_vecs = len(padded)
        corr = np.eye(n_vecs)
        for i in range(n_vecs):
            for j in range(i + 1, n_vecs):
                c = _correlation(padded[i], padded[j])
                if np.isfinite(c):
                    corr[i, j] = c
                    corr[j, i] = c

        adj = np.abs(corr)
        np.fill_diagonal(adj, 0.0)

        L = laplacian_matrix(adj, normalized=True)
        eigs = laplacian_eigenvalues(L)

        if len(eigs) >= 2 and np.any(np.isfinite(eigs)):
            result['laplacian_algebraic_connectivity'] = float(eigs[1])
            if eigs[-1] > 0:
                result['laplacian_spectral_gap'] = float(eigs[1] / eigs[-1])
            result['laplacian_n_components'] = float(np.sum(eigs < 1e-10))
            result['laplacian_max_eigenvalue'] = float(eigs[-1])
    except (ValueError, np.linalg.LinAlgError):
        pass
    except Exception as e:
        warnings.warn(f"trajectory_views.compute_laplacian_view: {type(e).__name__}: {e}", RuntimeWarning, stacklevel=2)

    return result


def compute_wavelet_view(
    trajectories: Dict[str, Dict[str, np.ndarray]],
    feature_cols: List[str],
    min_length: int = 8,
) -> Dict[str, float]:
    """
    Wavelet view: run wavelet_stability on each signal's feature trajectory.
    Extract dominant_scale, scale_entropy, energy_ratio.
    Aggregate across signals via nanmedian.

    Output keys: wavelet_{feature}_dominant_scale, wavelet_{feature}_scale_entropy,
                 wavelet_{feature}_energy_ratio
    """
    result = {}

    for feat in feature_cols:
        dom_scales = []
        entropies = []
        energy_ratios = []

        for sig_trajs in trajectories.values():
            if feat not in sig_trajs:
                continue
            arr = sig_trajs[feat]
            arr = arr[~np.isnan(arr)] if len(arr) > 0 else arr
            n = len(arr)
            if n < min_length:
                continue
            if np.std(arr) < 1e-10:
                dom_scales.append(0.0)
                entropies.append(0.0)
                energy_ratios.append(np.nan)
                continue

            try:
                r = _wavelet_stability(arr)
                dom_scales.append(float(r.get('dominant_scale', np.nan)))
                entropies.append(float(r.get('entropy', np.nan)))
                energy_ratios.append(float(r.get('energy_ratio', np.nan)))
            except (ValueError, TypeError):
                pass
            except Exception as e:
                warnings.warn(f"trajectory_views.compute_wavelet_view: {type(e).__name__}: {e}", RuntimeWarning, stacklevel=2)

        result[f'wavelet_{feat}_dominant_scale'] = float(np.nanmedian(dom_scales)) if dom_scales else np.nan
        result[f'wavelet_{feat}_scale_entropy'] = float(np.nanmedian(entropies)) if entropies else np.nan
        result[f'wavelet_{feat}_energy_ratio'] = float(np.nanmedian(energy_ratios)) if energy_ratios else np.nan

    return result
